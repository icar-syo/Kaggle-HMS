{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:33:26.666309Z","iopub.status.busy":"2024-04-07T13:33:26.665973Z","iopub.status.idle":"2024-04-07T13:33:26.681557Z","shell.execute_reply":"2024-04-07T13:33:26.680709Z","shell.execute_reply.started":"2024-04-07T13:33:26.666276Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:33:26.682926Z","iopub.status.busy":"2024-04-07T13:33:26.682627Z","iopub.status.idle":"2024-04-07T13:33:26.691626Z","shell.execute_reply":"2024-04-07T13:33:26.690823Z","shell.execute_reply.started":"2024-04-07T13:33:26.682902Z"},"trusted":true},"outputs":[],"source":["# Set to True for inference only, False for training\n","ONLY_INFERENCE = True\n","\n","# Configuration for model training\n","FOLDS = 5\n","EPOCHS = 4\n","BATCH = 32\n","NAME = 'None'\n","\n","SPEC_SIZE  = (512, 512, 3)\n","CLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n","N_CLASSES = len(CLASSES)\n","TARGETS = CLASSES"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:33:26.694526Z","iopub.status.busy":"2024-04-07T13:33:26.694129Z","iopub.status.idle":"2024-04-07T13:33:39.883372Z","shell.execute_reply":"2024-04-07T13:33:39.882149Z","shell.execute_reply.started":"2024-04-07T13:33:26.694495Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /kaggle/input/tf-efficientnet-whl-files\n","Processing /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl\n","Processing /kaggle/input/tf-efficientnet-whl-files/Keras_Applications-1.0.8-py3-none-any.whl (from efficientnet==1.1.1)\n","Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.1.1) (0.22.0)\n","Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (1.26.4)\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.1) (3.10.0)\n","Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (1.11.4)\n","Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (3.2.1)\n","Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (9.5.0)\n","Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (2.33.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (2023.12.9)\n","Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (21.3)\n","Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.1.1) (0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet==1.1.1) (3.1.1)\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"]}],"source":["!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:33:39.885382Z","iopub.status.busy":"2024-04-07T13:33:39.885013Z","iopub.status.idle":"2024-04-07T13:33:40.830310Z","shell.execute_reply":"2024-04-07T13:33:40.829297Z","shell.execute_reply.started":"2024-04-07T13:33:39.885344Z"},"trusted":true},"outputs":[],"source":["import gc\n","import os\n","import random\n","import sys\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import StratifiedGroupKFold\n","from tensorflow.keras import backend as K\n","from tqdm import tqdm \n","from scipy.ndimage import gaussian_filter\n","from scipy.signal import butter, filtfilt, iirnotch\n","from scipy.signal import spectrogram as spectrogram_np\n","\n","import efficientnet.tfkeras as efn\n","\n","sys.path.append(f'/kaggle/input/kaggle-kl-div')\n","from kaggle_kl_div import score"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:33:40.832219Z","iopub.status.busy":"2024-04-07T13:33:40.831438Z","iopub.status.idle":"2024-04-07T13:35:03.275978Z","shell.execute_reply":"2024-04-07T13:35:03.275006Z","shell.execute_reply.started":"2024-04-07T13:33:40.832191Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Apr  7 13:33:41 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0              27W / 250W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","CPU times: user 2.55 s, sys: 479 ms, total: 3.03 s\n","Wall time: 1min 22s\n"]}],"source":["%%time\n","!nvidia-smi\n","\n","# Installation of RAPIDS to Use cuSignal\n","!cp ../input/rapids/rapids.0.17.0 /opt/conda/envs/rapids.tar.gz\n","!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n","!rm /opt/conda/envs/rapids.tar.gz\n","\n","sys.path += [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"]\n","sys.path += [\"/opt/conda/envs/rapids/lib/python3.7\"]\n","sys.path += [\"/opt/conda/envs/rapids/lib\"]\n","!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n","\n","import cupy as cp\n","import cusignal"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:03.278294Z","iopub.status.busy":"2024-04-07T13:35:03.277536Z","iopub.status.idle":"2024-04-07T13:35:03.567853Z","shell.execute_reply":"2024-04-07T13:35:03.566850Z","shell.execute_reply.started":"2024-04-07T13:35:03.278250Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 1 GPU\n","Physical devices cannot be modified after being initialized\n","Mixed precision enabled\n"]}],"source":["# Set the visible CUDA devices\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","# Set the strategy for using GPUs\n","gpus = tf.config.list_physical_devices('GPU')\n","if len(gpus) <= 1:\n","    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n","    print(f'Using {len(gpus)} GPU')\n","else:\n","    strategy = tf.distribute.MirroredStrategy()\n","    print(f'Using {len(gpus)} GPUs')\n","\n","# Configure memory growth\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Enable or disable mixed precision\n","MIX = True\n","if MIX:\n","    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n","    print('Mixed precision enabled')\n","else:\n","    print('Using full precision')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:03.570678Z","iopub.status.busy":"2024-04-07T13:35:03.569814Z","iopub.status.idle":"2024-04-07T13:35:04.665815Z","shell.execute_reply":"2024-04-07T13:35:04.664466Z","shell.execute_reply.started":"2024-04-07T13:35:03.570622Z"},"trusted":true},"outputs":[],"source":["# Function to set random seed for reproducibility\n","def set_random_seed(seed: int = 42, deterministic: bool = False):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    tf.random.set_seed(seed)\n","    if deterministic:\n","        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","    else:\n","        os.environ.pop('TF_DETERMINISTIC_OPS', None)\n","\n","# Set a deterministic behavior\n","set_random_seed(deterministic=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:04.667470Z","iopub.status.busy":"2024-04-07T13:35:04.667143Z","iopub.status.idle":"2024-04-07T13:35:04.679184Z","shell.execute_reply":"2024-04-07T13:35:04.678255Z","shell.execute_reply.started":"2024-04-07T13:35:04.667439Z"},"trusted":true},"outputs":[],"source":["def create_train_data():\n","    # Read the dataset\n","    df = pd.read_csv('/kaggle/input/train-raw-csv/train.csv')\n","    \n","    # Create a new identifier combining multiple columns\n","    id_cols = ['eeg_id', 'spectrogram_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","    df['new_id'] = df[id_cols].astype(str).agg('_'.join, axis=1)\n","    \n","    # Calculate the sum of votes for each class\n","    df['sum_votes'] = df[CLASSES].sum(axis=1)\n","    \n","    # Group the data by the new identifier and aggregate various features\n","    agg_functions = {\n","        'eeg_id': 'first',\n","        'eeg_label_offset_seconds': ['min', 'max'],\n","        'spectrogram_label_offset_seconds': ['min', 'max'],\n","        'spectrogram_id': 'first',\n","        'patient_id': 'first',\n","        'expert_consensus': 'first',\n","        **{col: 'sum' for col in CLASSES},\n","        'sum_votes': 'mean',\n","    }\n","    grouped_df = df.groupby('new_id').agg(agg_functions).reset_index()\n","\n","    # Flatten the MultiIndex columns and adjust column names\n","    grouped_df.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0] for col in grouped_df.columns]\n","    grouped_df.columns = grouped_df.columns.str.replace('_first', '').str.replace('_sum', '').str.replace('_mean', '')\n","    \n","    # Normalize the class columns\n","    y_data = grouped_df[CLASSES].values\n","    y_data_normalized = y_data / y_data.sum(axis=1, keepdims=True)\n","    grouped_df[CLASSES] = y_data_normalized\n","\n","    # Split the dataset into high and low quality based on the sum of votes\n","    high_quality_df = grouped_df[grouped_df['sum_votes'] >= 10].reset_index(drop=True)\n","    low_quality_df = grouped_df[(grouped_df['sum_votes'] < 10) & (grouped_df['sum_votes'] >= 0)].reset_index(drop=True)\n","\n","    return high_quality_df, low_quality_df"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:04.682735Z","iopub.status.busy":"2024-04-07T13:35:04.682461Z","iopub.status.idle":"2024-04-07T13:35:06.425008Z","shell.execute_reply":"2024-04-07T13:35:06.424210Z","shell.execute_reply.started":"2024-04-07T13:35:04.682710Z"},"trusted":true},"outputs":[],"source":["high_quality_df,low_quality_df = create_train_data()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:06.426321Z","iopub.status.busy":"2024-04-07T13:35:06.426048Z","iopub.status.idle":"2024-04-07T13:35:06.438180Z","shell.execute_reply":"2024-04-07T13:35:06.437225Z","shell.execute_reply.started":"2024-04-07T13:35:06.426297Z"},"trusted":true},"outputs":[],"source":["class DataGenerator(tf.keras.utils.Sequence):\n","\n","    def __init__(self, data, batch_size=32, shuffle=False, mode='train'):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.mode = mode\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        \"\"\"Denotes the number of batches per epoch.\"\"\"\n","        return int(np.ceil(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        \"\"\"Generate one batch of data.\"\"\"\n","        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n","        X, y = self.__data_generation(indexes)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        \"\"\"Updates indexes after each epoch.\"\"\"\n","        self.indexes = np.arange(len(self.data))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, indexes):\n","        \"\"\"Generates data containing batch_size samples.\"\"\"\n","        # Initialization\n","        X = np.zeros((len(indexes), *SPEC_SIZE), dtype='float32')\n","        y = np.zeros((len(indexes), len(CLASSES)), dtype='float32')\n","\n","        # Generate data\n","        for j, i in enumerate(indexes):\n","            row = self.data.iloc[i]\n","            eeg_id = row['eeg_id']\n","            spec_offset = int(row['spectrogram_label_offset_seconds_min'])\n","            eeg_offset = int(row['eeg_label_offset_seconds_min'])\n","            file_path = f'/kaggle/input/3-diff-time-specs-hms/images/{eeg_id}_{spec_offset}_{eeg_offset}.npz'\n","            data = np.load(file_path)\n","            eeg_data = data['final_image']\n","            eeg_data_expanded = np.repeat(eeg_data[:, :, np.newaxis], 3, axis=2)\n","\n","            X[j] = eeg_data_expanded\n","            if self.mode != 'test':\n","                y[j] = row[CLASSES]\n","\n","        return X, y"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:06.439753Z","iopub.status.busy":"2024-04-07T13:35:06.439421Z","iopub.status.idle":"2024-04-07T13:35:13.490894Z","shell.execute_reply":"2024-04-07T13:35:13.490077Z","shell.execute_reply.started":"2024-04-07T13:35:06.439722Z"},"trusted":true},"outputs":[],"source":["# train_raw_csv\n","# eeg2spec-new\n","import sys\n","import os\n","import gc\n","import copy\n","import yaml\n","import random\n","import shutil\n","from time import time\n","import typing as tp\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.cuda import amp\n","\n","import timm\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:13.492278Z","iopub.status.busy":"2024-04-07T13:35:13.492013Z","iopub.status.idle":"2024-04-07T13:35:13.498696Z","shell.execute_reply":"2024-04-07T13:35:13.497726Z","shell.execute_reply.started":"2024-04-07T13:35:13.492254Z"},"trusted":true},"outputs":[],"source":["class HMSHBACSpecModel(nn.Module):\n","\n","    def __init__(\n","            self,\n","            model_name: str,\n","            pretrained: bool,\n","            in_channels: int,\n","            num_classes: int,\n","        ):\n","        super().__init__()\n","        self.model = timm.create_model(\n","            model_name=model_name, pretrained=pretrained,\n","            num_classes=num_classes, in_chans=in_channels)\n","\n","    def forward(self, x):\n","        h = self.model(x)      \n","\n","        return h"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:38:43.450620Z","iopub.status.busy":"2024-04-07T13:38:43.450223Z","iopub.status.idle":"2024-04-07T13:38:43.486990Z","shell.execute_reply":"2024-04-07T13:38:43.485960Z","shell.execute_reply.started":"2024-04-07T13:38:43.450592Z"}},"outputs":[],"source":["#### FilePath = tp.Union[str, Path]\n","EegIds = tp.Union[str, Path]\n","Label = tp.Union[int, float, np.ndarray]\n","\n","class HMSHBACSpecDataset(torch.utils.data.Dataset):\n","\n","    def __init__(\n","        self,\n","        eeg_ids: tp.Sequence[EegIds],\n","        image_paths: tp.Sequence[FilePath],\n","        labels: tp.Sequence[Label],\n","        transform: A.Compose,\n","    ):\n","        self.eeg_ids = eeg_ids\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index: int):\n","        img_path = self.image_paths[index]\n","        eeg_id = self.eeg_ids[index]       \n","        label = self.labels[index]\n","#         print(\"img_path:\",img_path)\n","        file_path = f'/kaggle/input/3-diff-time-specs-hms/images/{img_path}.npz'\n","        data = np.load(file_path)\n","        data = data['final_image']\n","        result_img = data[..., None]\n","    \n","        img = self._apply_transform(result_img)\n","    \n","        return {\"data\": img, \"target\": label}\n","\n","    def _apply_transform(self, img: np.ndarray):\n","        \"\"\"apply transform to image and mask\"\"\"\n","        transformed = self.transform(image=img)\n","        img = transformed[\"image\"]\n","        return img\n","    \n","class KLDivLossWithLogits(nn.KLDivLoss):\n","\n","    def __init__(self):\n","        super().__init__(reduction=\"batchmean\")\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y,  dim=1)\n","        loss = super().forward(y, t)\n","\n","        return loss\n","\n","\n","class KLDivLossWithLogitsForVal(nn.KLDivLoss):\n","    \n","    def __init__(self):\n","        \"\"\"\"\"\"\n","        super().__init__(reduction=\"batchmean\")\n","        self.log_prob_list  = []\n","        self.label_list = []\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y, dim=1)\n","        self.log_prob_list.append(y.numpy())\n","        self.label_list.append(t.numpy())\n","        \n","    def compute(self):\n","        log_prob = np.concatenate(self.log_prob_list, axis=0)\n","        label = np.concatenate(self.label_list, axis=0)\n","        final_metric = super().forward(\n","            torch.from_numpy(log_prob),\n","            torch.from_numpy(label)\n","        ).item()\n","        self.log_prob_list = []\n","        self.label_list = []\n","        \n","        return final_metric\n","    \n","class CFG:\n","    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n","    img_size = 512\n","    max_epoch = 10\n","    batch_size = 32\n","    lr = 1.0e-03\n","    weight_decay = 1.0e-02\n","    es_patience =  3\n","    seed = 1086\n","    deterministic = True\n","    enable_amp = True\n","    device = \"cuda\"\n","    \n","def set_random_seed(seed: int = 42, deterministic: bool = False):\n","    \"\"\"Set seeds\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n","    \n","def to_device(\n","    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n","    device: torch.device, *args, **kwargs\n","):\n","    if isinstance(tensors, tuple):\n","        return (t.to(device, *args, **kwargs) for t in tensors)\n","    elif isinstance(tensors, dict):\n","        return {\n","            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n","    else:\n","        return tensors.to(device, *args, **kwargs)\n","    \n","def get_path_label(val_fold, train_all: pd.DataFrame):\n","    \"\"\"Get file path and target info.\"\"\"\n","    \n","    train_idx = train_all[train_all[\"fold\"] != val_fold].index.values\n","    val_idx   = train_all[train_all[\"fold\"] == val_fold].index.values\n","    img_paths = []\n","    eeg_ids = []\n","    labels = train_all[CLASSES].values\n","    for label_id in train_all[\"new_id\"].values:\n","#         img_path = TRAIN_SPEC_SPLIT / f\"{label_id}.npy\"\n","        train1 = train[train['new_id']==label_id]\n","        eeg_id = train1['eeg_id'].values[0]\n","        spec_offset = int(train1['spectrogram_label_offset_seconds_min'].values[0])\n","        eeg_offset = int(train1['eeg_label_offset_seconds_min'].values[0])\n","#         print(f\"eeg_id:{eeg_id},spec_off:{spec_offset},eeg_off:{eeg_offset}\")\n","        path = str(eeg_id)+'_'+str(spec_offset)+'_'+str(eeg_offset)\n","#         file_path = f'/kaggle/input/3-diff-time-specs-hms/images/{eeg_id}_{spec_offset}_{eeg_offset}.npz'\n","#         img_path = label_id\n","        eeg_ids.append(eeg_id)\n","        img_paths.append(path)\n","\n","    train_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in train_idx],\n","        \"image_paths\": [img_paths[idx] for idx in train_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in train_idx]}\n","\n","    val_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in val_idx],\n","        \"image_paths\": [img_paths[idx] for idx in val_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in val_idx]}\n","    \n","    return train_data, val_data, train_idx, val_idx\n","\n","def time_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用时间遮蔽。\n","    \n","    参数：\n","    - spec: 输入的频谱图，形状为 [time_steps, freq_bins, channels]\n","    - max_time_mask: 最大的时间遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用时间遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = time_steps - int(max_mask*time_steps)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*time_steps))\n","    masked_spec[:, mask_start:mask_end, :] = 0\n","    return masked_spec\n","\n","\n","def freq_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用频率遮蔽。\n","    参数：\n","    - spec: 输入的频谱图，形状为 [time_steps, freq_bins, channels]\n","    - max_freq_mask: 最大的频率遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用频率遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = freq_bins - int(max_mask*freq_bins)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*freq_bins))\n","    masked_spec[mask_start:mask_end, :, :] = 0\n","    return masked_spec\n","\n","\n","class TimeMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(TimeMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, image, **params):\n","        return time_masking(image, self.max_mask)\n","\n","class FreqMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(FreqMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, spec, **params):\n","        return freq_masking(spec, self.max_mask)\n","def get_transforms(CFG):\n","    train_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        TimeMasking(max_mask=0.2, p=0.5),\n","        FreqMasking(max_mask=0.2, p=0.5),\n","        ToTensorV2(p=1.0)\n","    ])\n","    val_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        ToTensorV2(p=1.0)\n","    ])\n","    return train_transform, val_transform"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:15.470331Z","iopub.status.busy":"2024-04-07T13:35:15.469476Z","iopub.status.idle":"2024-04-07T13:35:15.490587Z","shell.execute_reply":"2024-04-07T13:35:15.489708Z","shell.execute_reply.started":"2024-04-07T13:35:15.470297Z"},"trusted":true},"outputs":[],"source":["def train_one_fold(CFG, val_fold, train_all, output_path,fold_id):\n","    \"\"\"Main\"\"\"\n","    torch.backends.cudnn.benchmark = True\n","    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n","    device = torch.device(CFG.device)\n","    \n","    train_path_label, val_path_label, _, _ = get_path_label(val_fold, train_all)\n","    train_transform, val_transform = get_transforms(CFG)\n","    \n","    train_dataset = HMSHBACSpecDataset(**train_path_label, transform=train_transform)\n","    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n","    \n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n","    val_loader = torch.utils.data.DataLoader(\n","        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n","    \n","    model = HMSHBACSpecModel(\n","        model_name=CFG.model_name, pretrained=True, num_classes=6, in_channels=1)\n","#     model.load_state_dict(torch.load('/kaggle/input/new-eeg2spec-v3-2stage-1-10fold-fold3/best_model_fold3.pth', map_location=device))\n","    model.to(device)\n","    \n","    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    scheduler = lr_scheduler.OneCycleLR(\n","        optimizer=optimizer, epochs=CFG.max_epoch,\n","        pct_start=0.0, steps_per_epoch=len(train_loader),\n","        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n","    )\n","    \n","    loss_func = KLDivLossWithLogits()\n","    loss_func.to(device)\n","    loss_func_val = KLDivLossWithLogitsForVal()\n","    \n","    use_amp = CFG.enable_amp\n","    scaler = amp.GradScaler(enabled=use_amp)\n","    \n","    best_val_loss = 1.0e+09\n","    best_epoch = 0\n","    train_loss = 0\n","    \n","    for epoch in range(1, CFG.max_epoch + 1):\n","        epoch_start = time()\n","        model.train()\n","        bar = tqdm(enumerate(train_loader), total=len(train_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","#         for batch in train_loader:\n","            batch = to_device(batch, device)\n","            x, t = batch[\"data\"], batch[\"target\"]\n","                \n","            optimizer.zero_grad()\n","            with amp.autocast(use_amp):\n","                y = model(x)\n","                loss = loss_func(y, t)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            train_loss += loss.item()\n","            loss_show = float(train_loss/bs)\n","#             bar.set_postfix(Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n","            bar.set_postfix(Epoch=epoch, Train_Loss=loss_show, LR=optimizer.param_groups[0]['lr'])\n","\n","        train_loss /= len(train_loader)\n","            \n","        model.eval()\n","        bar = tqdm(enumerate(val_loader), total=len(val_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","#         for batch in val_loader:\n","            x, t = batch[\"data\"], batch[\"target\"]\n","            x = to_device(x, device)\n","            with torch.no_grad(), amp.autocast(use_amp):\n","                y = model(x)\n","            y = y.detach().cpu().to(torch.float32)\n","            loss_func_val(y, t)\n","#             val_loss1 = loss_func_val.compute() \n","            bar.set_postfix(Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n","        val_loss = loss_func_val.compute()        \n","        if val_loss < best_val_loss:\n","            best_epoch = epoch\n","            best_val_loss = val_loss\n","            # print(\"save model\")\n","            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n","        \n","        elapsed_time = time() - epoch_start\n","        print(\n","            f\"[fold {fold_id}  epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f},best loss: {best_val_loss: .6f},best_epoch: {best_epoch}, elapsed_time: {elapsed_time: .3f}\")\n","        \n","        if epoch - best_epoch > CFG.es_patience:\n","            print(\"Early Stopping!\")\n","            break\n","            \n","        train_loss = 0\n","            \n","    return val_fold, best_epoch, best_val_loss\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:15.492072Z","iopub.status.busy":"2024-04-07T13:35:15.491771Z","iopub.status.idle":"2024-04-07T13:35:15.503263Z","shell.execute_reply":"2024-04-07T13:35:15.502550Z","shell.execute_reply.started":"2024-04-07T13:35:15.492047Z"},"trusted":true},"outputs":[],"source":["FOLDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","N_FOLDS = len(FOLDS)\n","RANDAM_SEED = 1086"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:15.504617Z","iopub.status.busy":"2024-04-07T13:35:15.504326Z","iopub.status.idle":"2024-04-07T13:35:15.513267Z","shell.execute_reply":"2024-04-07T13:35:15.512517Z","shell.execute_reply.started":"2024-04-07T13:35:15.504594Z"},"trusted":true},"outputs":[],"source":["train = low_quality_df"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:15.514449Z","iopub.status.busy":"2024-04-07T13:35:15.514178Z","iopub.status.idle":"2024-04-07T13:35:17.382377Z","shell.execute_reply":"2024-04-07T13:35:17.381510Z","shell.execute_reply.started":"2024-04-07T13:35:15.514426Z"},"trusted":true},"outputs":[],"source":["sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n","\n","for fold_id, (_, val_idx) in enumerate(\n","    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n","):\n","    train.loc[val_idx, \"fold\"] = fold_id"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T13:35:17.383888Z","iopub.status.busy":"2024-04-07T13:35:17.383572Z","iopub.status.idle":"2024-04-07T13:36:00.200424Z","shell.execute_reply":"2024-04-07T13:36:00.198724Z","shell.execute_reply.started":"2024-04-07T13:35:17.383860Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[fold8]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"827f01ec534546e3883307d500053af5","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f119412d32ed49a98f35b3148164b177","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/387 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[[-1.4446659  -1.4274988  -1.4268126  ... -1.397358   -1.2328732\n","  -1.0415576 ]\n"," [-1.3464026  -1.336714   -1.349985   ... -1.2705965  -1.1206894\n","  -0.93675005]\n"," [-1.5649002  -1.5682733  -1.5820396  ... -1.1766839  -1.00274\n","  -0.88273436]\n"," ...\n"," [ 2.4203324   2.4069943   2.3899126  ...  1.9683442   2.0024343\n","   2.0184422 ]\n"," [ 1.7595029   1.7844515   1.7994947  ...  1.8803232   1.8360085\n","   1.7892601 ]\n"," [ 1.947715    1.9416661   1.9334404  ...  1.6950381   1.5780215\n","   1.4579642 ]]\n","[[-0.74602664 -0.7536557  -0.75464904 ...  1.1151214   0.06925447\n","  -0.32068014]\n"," [-1.0448215  -1.0469887  -1.0501493  ...  1.1879349   0.07748546\n","  -0.36013702]\n"," [-1.0805839  -1.0791351  -1.0809426  ...  1.1485903   0.13246831\n","  -0.14829001]\n"," ...\n"," [ 1.7849009   1.6693755   1.5235     ...  2.7164388   2.6961882\n","   2.6555886 ]\n"," [ 2.0372066   1.8368629   1.6371721  ...  2.8863175   2.9340482\n","   2.9939175 ]\n"," [ 2.0064323   1.7717342   1.5371313  ...  2.7244487   2.7614412\n","   2.8561225 ]][[-1.4730122 -1.477437  -1.4823003 ... -1.1924944 -1.2829802 -1.5162495]\n"," [-1.4129006 -1.4292215 -1.4476093 ... -1.2317    -1.1575115 -1.4083235]\n"," [-1.3497313 -1.3515844 -1.3586574 ... -1.2744536 -1.1405157 -1.1237193]\n"," ...\n"," [ 1.8300129  1.75488    1.7119424 ...  1.594689   1.5304049  1.4889488]\n"," [ 1.8209867  1.8051429  1.7967963 ...  1.8236446  1.7937477  1.7701195]\n"," [ 1.6308327  1.6113927  1.5871489 ...  1.8027585  1.8083813  1.8267784]]\n","\n","[[-1.6086974 -1.5792991 -1.5364003 ... -1.7618959 -1.7618959 -1.7618959]\n"," [-1.4436712 -1.4150896 -1.386455  ... -1.7618958 -1.7618958 -1.7618958]\n"," [-1.485867  -1.4835624 -1.4955057 ... -1.7618959 -1.7618959 -1.7618959]\n"," ...\n"," [ 0.7921474  0.8343804  0.9023892 ...  1.4455149  1.3461001  1.4111252]\n"," [ 1.0960679  1.1148903  1.1461926 ...  1.296396   1.3427229  1.4144666]\n"," [ 0.9980155  0.9492843  0.880695  ...  1.2622274  1.313945   1.3441492]]\n","[[-1.4977864  -1.5193207  -1.5334811  ... -1.2752265  -1.4291439\n","  -1.7002082 ]\n"," [-1.5993371  -1.6089731  -1.6120979  ... -1.2867849  -1.3798553\n","  -1.6701345 ]\n"," [-1.4621477  -1.4777237  -1.4832523  ... -1.2488487  -1.3158965\n","  -1.5387335 ]\n"," ...\n"," [ 2.1241293   2.120265    2.1154034  ...  1.4954443   1.4827347\n","   1.4879669 ]\n"," [ 1.7144783   1.6326592   1.5096892  ...  1.2905056   1.2860739\n","   1.2717934 ]\n"," [ 1.3959386   1.3152096   1.197337   ...  0.97932994  0.95189947\n","   0.8798287 ]][[-1.4764029  -1.4829694  -1.4919894  ... -0.8296074  -0.5312937\n","  -1.4374615 ]\n"," [-1.3452144  -1.334701   -1.3522321  ... -0.6652385  -0.3882984\n","  -1.2063074 ]\n"," [-0.7649963  -0.76499206 -0.7693427  ... -0.49775517 -0.44594702\n","  -1.05965   ]\n"," ...\n"," [ 2.3737452   2.3722427   2.3637006  ...  0.8242041   0.84901005\n","   0.8700652 ]\n"," [ 1.4122015   1.4181824   1.395079   ...  1.0693197   1.044676\n","   1.0344257 ]\n"," [ 0.725387    0.69902056  0.60811913 ...  0.99160886  0.8738551\n","   0.77659357]]\n","\n","[[-0.92966855 -0.92966866 -0.92966855 ... -1.0305923  -1.0305924\n","  -1.0305923 ]\n"," [-0.9140707  -0.91758174 -0.92108685 ... -1.0305923  -1.0305924\n","  -1.0305923 ]\n"," [-0.8877828  -0.88631546 -0.88712543 ... -1.0305923  -1.0305924\n","  -1.0305923 ]\n"," ...\n"," [ 1.0233833   1.0947915   1.2539973  ...  1.7165072   1.713686\n","   1.7161288 ]\n"," [ 1.962384    1.9809406   2.0066633  ...  1.5239887   1.5186452\n","   1.5095829 ]\n"," [ 1.1530513   1.1568526   1.1737168  ...  1.1210597   1.1372703\n","   1.1607627 ]]\n","[[-1.7236092  -1.7300469  -1.7365737  ... -1.8325307  -1.8615912\n","  -1.9349463 ]\n"," [-1.5542959  -1.5758047  -1.597339   ... -1.8252392  -1.8062713\n","  -1.8326612 ]\n"," [-1.3652468  -1.3709528  -1.3754876  ... -1.7681433  -1.876229\n","  -1.9176528 ]\n"," ...\n"," [ 0.53817767  0.47933677  0.38345414 ...  1.7049062   1.6603985\n","   1.6155518 ]\n"," [ 0.37017718  0.3907106   0.4075095  ...  1.187832    1.2663777\n","   1.3543974 ]\n"," [ 0.28180403  0.19495265  0.1636934  ...  0.71851575  0.7477431\n","   0.9338223 ]]\n","[[-1.3326156  -1.320292   -1.303205   ... -1.9392121  -1.5471303\n","  -1.1090857 ]\n"," [-1.4913273  -1.4780293  -1.467754   ... -1.5477471  -1.2156938\n","  -0.94004935]\n"," [-1.0996244  -1.0913634  -1.0734748  ... -1.357449   -1.2914107\n","  -1.1597192 ]\n"," ...\n"," [ 1.3789009   1.291328    1.1660609  ... -0.29134098 -0.44486004\n","  -0.53986615]\n"," [ 1.1270611   1.0695034   1.0150054  ... -0.25024405 -0.25960308\n","  -0.2683602 ]\n"," [ 1.4175223   1.3693917   1.302849   ... -0.00656487 -0.01117181\n","  -0.04762306]]\n"]},{"ename":"NameError","evalue":"Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_34/2858983080.py\", line 31, in __getitem__\n    print(data1)\nNameError: name 'data1' is not defined. Did you mean: 'data'?\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     output_path\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     score_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfold_id\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(score_list)\n","Cell \u001b[0;32mIn[18], line 46\u001b[0m, in \u001b[0;36mtrain_one_fold\u001b[0;34m(CFG, val_fold, train_all, output_path, fold_id)\u001b[0m\n\u001b[1;32m     44\u001b[0m         bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader))\n\u001b[1;32m     45\u001b[0m         bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m bar:\n\u001b[1;32m     47\u001b[0m             bs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#         for batch in train_loader:\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_34/2858983080.py\", line 31, in __getitem__\n    print(data1)\nNameError: name 'data1' is not defined. Did you mean: 'data'?\n"]}],"source":["score_list = []\n","for fold_id in [0,1,2,3,4,5,6,7,8,9]:\n","    output_path = Path(f\"fold{fold_id}\")\n","    output_path.mkdir(exist_ok=True)\n","    print(f\"[fold{fold_id}]\")\n","    score_list.append(train_one_fold(CFG, fold_id, train, output_path,fold_id))\n","print(score_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:36:00.201881Z","iopub.status.idle":"2024-04-07T13:36:00.202222Z","shell.execute_reply":"2024-04-07T13:36:00.202075Z","shell.execute_reply.started":"2024-04-07T13:36:00.202062Z"},"trusted":true},"outputs":[],"source":["best_log_list = []\n","for (fold_id, best_epoch, _) in score_list:\n","    \n","    exp_dir_path = Path(f\"fold{fold_id}\")\n","    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n","    copy_to = f\"./best_model_fold{fold_id}.pth\"\n","    shutil.copy(best_model_path, copy_to)\n","    \n","    for p in exp_dir_path.glob(\"*.pth\"):\n","        p.unlink()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":492658,"sourceId":2378330,"sourceType":"datasetVersion"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4462774,"sourceId":7654739,"sourceType":"datasetVersion"},{"datasetId":4532886,"sourceId":7754261,"sourceType":"datasetVersion"},{"sourceId":158958765,"sourceType":"kernelVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
