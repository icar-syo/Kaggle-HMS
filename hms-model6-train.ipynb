{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","import gc\n","import copy\n","import yaml\n","import random\n","import shutil\n","from time import time\n","import typing as tp\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.cuda import amp\n","\n","import timm\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","train_fold = 3\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","ROOT = Path.cwd().parent\n","INPUT = ROOT / \"input\"\n","OUTPUT = ROOT / \"output\"\n","SRC = ROOT / \"src\"\n","\n","DATA = INPUT / \"train-raw-csv\"\n","TRAIN_SPEC = DATA / \"train_spectrograms\"\n","TEST_SPEC = DATA / \"test_spectrograms\"\n","\n","TMP = ROOT / \"tmp\"\n","TRAIN_SPEC_SPLIT = TMP / \"train_spectrograms_split\"\n","TEST_SPEC_SPLIT = TMP / \"test_spectrograms_split\"\n","TMP.mkdir(exist_ok=True)\n","TRAIN_SPEC_SPLIT.mkdir(exist_ok=True)\n","TEST_SPEC_SPLIT.mkdir(exist_ok=True)\n","\n","\n","RANDAM_SEED = 1086\n","CLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n","N_CLASSES = len(CLASSES)\n","# FOLDS = [0, 1, 2, 3, 4]\n","FOLDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","N_FOLDS = len(FOLDS)\n","\n","train = pd.read_csv(DATA / \"train.csv\")\n","import pandas as pd\n","\n","columns = ['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","\n","unique_rows = train.drop_duplicates(subset=columns, keep='first').reset_index(drop=True)\n","\n","train = unique_rows\n","\n","train['total_votes'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n","train['target'] = train['expert_consensus']\n","train[CLASSES] /= train[CLASSES].sum(axis=1).values[:, None]\n","pop_1_idx = train['total_votes'] < 10\n","train_pop_1 = train[pop_1_idx].copy().reset_index(drop=True)\n","train_pop_2 = train[~pop_1_idx].copy().reset_index(drop=True)\n","\n","train = train_pop_1\n","\n","train[\"fold\"] = -1\n","\n","sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n","\n","for fold_id, (_, val_idx) in enumerate(\n","    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n","):\n","    train.loc[val_idx, \"fold\"] = fold_id\n","    \n","    \n","all_eegs = np.load('/kaggle/input/eeg2spec-new/eeg2spec_new.npy',allow_pickle=True).item()\n","all_eegs10s = np.load('/kaggle/input/eeg2spec-new-10s/eeg2spec_new_10s.npy',allow_pickle=True).item()\n","max_int_value = (1 << 31) - 1\n","\n","keys_to_remove = []\n","\n","for key, value_list in list(all_eegs.items()):\n","    if key <= 0:\n","        truncated_value = key\n","        n = 32  # 假设为32位整数\n","        # 原始值 = 截断值 + 2^(n)\n","        original_value = truncated_value + (1 << n)\n","        keys_to_remove.append(key)\n","        all_eegs[original_value] = value_list\n","\n","# 在迭代结束后删除需要删除的键\n","for key in keys_to_remove:\n","    del all_eegs[key]\n","\n","raw_eegs = all_eegs\n","\n","all_eeg2spec = raw_eegs\n","\n","\n","\n","\n","keys_to_remove1 = []\n","\n","for key, value_list in list(all_eegs10s.items()):\n","    if key <= 0:\n","        truncated_value = key\n","        n = 32  # 假设为32位整数\n","        # 原始值 = 截断值 + 2^(n)\n","        original_value = truncated_value + (1 << n)\n","        keys_to_remove1.append(key)\n","        all_eegs10s[original_value] = value_list\n","\n","# 在迭代结束后删除需要删除的键\n","for key in keys_to_remove1:\n","    del all_eegs10s[key]\n","\n","# raw_eegs = all_eegs\n","\n","all_eeg2spec1 = all_eegs10s\n","\n","class HMSHBACSpecModel(nn.Module):\n","\n","    def __init__(\n","            self,\n","            model_name: str,\n","            pretrained: bool,\n","            in_channels: int,\n","            num_classes: int,\n","        ):\n","        super().__init__()\n","        self.model = timm.create_model(\n","            model_name=model_name, pretrained=pretrained,\n","            num_classes=num_classes, in_chans=in_channels)\n","\n","    def forward(self, x):\n","        h = self.model(x)      \n","\n","        return h\n","    \n","    \n","FilePath = tp.Union[str, Path]\n","EegIds = tp.Union[str, Path]\n","Label = tp.Union[int, float, np.ndarray]\n","\n","class HMSHBACSpecDataset(torch.utils.data.Dataset):\n","\n","    def __init__(\n","        self,\n","        eeg_ids: tp.Sequence[EegIds],\n","        image_paths: tp.Sequence[FilePath],\n","        labels: tp.Sequence[Label],\n","        transform: A.Compose,\n","    ):\n","        self.eeg_ids = eeg_ids\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index: int):\n","        img_path = self.image_paths[index]\n","        eeg_id = self.eeg_ids[index]       \n","        label = self.labels[index]\n","        \n","        #  (516, 448)\n","        data = all_eeg2spec[img_path]\n","        # Fill missing values with the specified constant\n","        mask = np.isnan(data)\n","        data[mask] = -1\n","        data = np.clip(data, np.exp(-6), np.exp(10))\n","        data = np.log(data)\n","        data_mean = data.mean(axis=(0, 1))\n","        data = data - data_mean\n","        img_std = data.std(axis=(0, 1))\n","        eps = 1e-6\n","        data = data / (img_std + eps)   # 400-300\n","        \n","        # (516, 85)\n","        data1 = all_eeg2spec1[img_path]\n","        # Fill missing values with the specified constant\n","        mask1 = np.isnan(data1)\n","        data1[mask1] = -1\n","        data1 = np.clip(data1, np.exp(-6), np.exp(10))\n","        data1 = np.log(data1)\n","        data_mean1 = data1.mean(axis=(0, 1))\n","        data1 = data1 - data_mean1\n","        img_std1 = data1.std(axis=(0, 1))\n","        eps = 1e-6\n","        data1 = data1 / (img_std1 + eps)   # 400-300\n","\n","        result_img = np.zeros((516, 533), dtype=data1.dtype)\n","        result_img[:,:448]=data\n","        result_img[:,448:]=data1\n","        result_img = result_img[..., None]\n","    \n","        img = self._apply_transform(result_img)\n","    \n","        return {\"data\": img, \"target\": label}\n","\n","    def _apply_transform(self, img: np.ndarray):\n","        \"\"\"apply transform to image and mask\"\"\"\n","        transformed = self.transform(image=img)\n","        img = transformed[\"image\"]\n","        return img\n","    \n","class KLDivLossWithLogits(nn.KLDivLoss):\n","\n","    def __init__(self):\n","        super().__init__(reduction=\"batchmean\")\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y,  dim=1)\n","        loss = super().forward(y, t)\n","\n","        return loss\n","\n","\n","class KLDivLossWithLogitsForVal(nn.KLDivLoss):\n","    \n","    def __init__(self):\n","        \"\"\"\"\"\"\n","        super().__init__(reduction=\"batchmean\")\n","        self.log_prob_list  = []\n","        self.label_list = []\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y, dim=1)\n","        self.log_prob_list.append(y.numpy())\n","        self.label_list.append(t.numpy())\n","        \n","    def compute(self):\n","        log_prob = np.concatenate(self.log_prob_list, axis=0)\n","        label = np.concatenate(self.label_list, axis=0)\n","        final_metric = super().forward(\n","            torch.from_numpy(log_prob),\n","            torch.from_numpy(label)\n","        ).item()\n","        self.log_prob_list = []\n","        self.label_list = []\n","        \n","        return final_metric\n","    \n","class CFG:\n","    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n","    img_size = 512\n","    max_epoch = 10\n","    batch_size = 32\n","    lr = 1.0e-03\n","    weight_decay = 1.0e-02\n","    es_patience =  5\n","    seed = 1086\n","    deterministic = True\n","    enable_amp = True\n","    device = \"cuda\"\n","    \n","def set_random_seed(seed: int = 42, deterministic: bool = False):\n","    \"\"\"Set seeds\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n","    \n","def to_device(\n","    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n","    device: torch.device, *args, **kwargs\n","):\n","    if isinstance(tensors, tuple):\n","        return (t.to(device, *args, **kwargs) for t in tensors)\n","    elif isinstance(tensors, dict):\n","        return {\n","            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n","    else:\n","        return tensors.to(device, *args, **kwargs)\n","    \n","def get_path_label(val_fold, train_all: pd.DataFrame):\n","    \"\"\"Get file path and target info.\"\"\"\n","    \n","    train_idx = train_all[train_all[\"fold\"] != val_fold].index.values\n","    val_idx   = train_all[train_all[\"fold\"] == val_fold].index.values\n","    img_paths = []\n","    eeg_ids = []\n","    labels = train_all[CLASSES].values\n","    for label_id in train_all[\"label_id\"].values:\n","#         img_path = TRAIN_SPEC_SPLIT / f\"{label_id}.npy\"\n","        train1 = train[train['label_id']==label_id]\n","        eeg_id = train1['eeg_id'].values[0]\n","        \n","        img_path = label_id\n","        eeg_ids.append(eeg_id)\n","        img_paths.append(img_path)\n","\n","    train_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in train_idx],\n","        \"image_paths\": [img_paths[idx] for idx in train_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in train_idx]}\n","\n","    val_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in val_idx],\n","        \"image_paths\": [img_paths[idx] for idx in val_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in val_idx]}\n","    \n","    return train_data, val_data, train_idx, val_idx\n","\n","def time_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用时间遮蔽。\n","    \n","    参数：\n","    - spec: 输入的频谱图，形状为 \n","    - max_time_mask: 最大的时间遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用时间遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = time_steps - int(max_mask*time_steps)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*time_steps))\n","    masked_spec[:, mask_start:mask_end, :] = 0\n","    return masked_spec\n","\n","\n","def freq_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用频率遮蔽。\n","    参数：\n","    - spec: 输入的频谱图，形状为 \n","    - max_freq_mask: 最大的频率遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用频率遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = freq_bins - int(max_mask*freq_bins)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*freq_bins))\n","    masked_spec[mask_start:mask_end, :, :] = 0\n","    return masked_spec\n","\n","\n","class TimeMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(TimeMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, image, **params):\n","        return time_masking(image, self.max_mask)\n","\n","class FreqMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(FreqMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, spec, **params):\n","        return freq_masking(spec, self.max_mask)\n","def get_transforms(CFG):\n","    train_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        TimeMasking(max_mask=0.2, p=0.5),\n","        FreqMasking(max_mask=0.2, p=0.5),\n","        ToTensorV2(p=1.0)\n","    ])\n","    val_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        ToTensorV2(p=1.0)\n","    ])\n","    return train_transform, val_transform\n","\n","\n","def train_one_fold(CFG, val_fold, train_all, output_path,fold_id,stage_id):\n","    \"\"\"Main\"\"\"\n","    torch.backends.cudnn.benchmark = True\n","    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n","    device = torch.device(CFG.device)\n","    \n","    train_path_label, val_path_label, _, _ = get_path_label(val_fold, train_all)\n","    train_transform, val_transform = get_transforms(CFG)\n","    \n","    train_dataset = HMSHBACSpecDataset(**train_path_label, transform=train_transform)\n","    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n","    \n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n","    val_loader = torch.utils.data.DataLoader(\n","        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n","    \n","    model = HMSHBACSpecModel(\n","        model_name=CFG.model_name, pretrained=True, num_classes=6, in_channels=1)\n","    if stage_id == 2:\n","        model.load_state_dict(torch.load(f'./stage1/best_model_fold{val_fold}.pth', map_location=device))\n","    model.to(device)\n","    \n","    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    scheduler = lr_scheduler.OneCycleLR(\n","        optimizer=optimizer, epochs=CFG.max_epoch,\n","        pct_start=0.0, steps_per_epoch=len(train_loader),\n","        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n","    )\n","    \n","    loss_func = KLDivLossWithLogits()\n","    loss_func.to(device)\n","    loss_func_val = KLDivLossWithLogitsForVal()\n","    \n","    use_amp = CFG.enable_amp\n","    scaler = amp.GradScaler(enabled=use_amp)\n","    \n","    best_val_loss = 1.0e+09\n","    best_epoch = 0\n","    train_loss = 0\n","    \n","    for epoch in range(1, CFG.max_epoch + 1):\n","        epoch_start = time()\n","        model.train()\n","        bar = tqdm(enumerate(train_loader), total=len(train_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","#         for batch in train_loader:\n","            batch = to_device(batch, device)\n","            x, t = batch[\"data\"], batch[\"target\"]\n","                \n","            optimizer.zero_grad()\n","            with amp.autocast(use_amp):\n","                y = model(x)\n","                loss = loss_func(y, t)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            train_loss += loss.item()\n","            loss_show = float(train_loss/bs)\n","#             bar.set_postfix(Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n","            bar.set_postfix(Epoch=epoch, Train_Loss=loss_show, LR=optimizer.param_groups[0]['lr'])\n","\n","        train_loss /= len(train_loader)\n","            \n","        model.eval()\n","        bar = tqdm(enumerate(val_loader), total=len(val_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","#         for batch in val_loader:\n","            x, t = batch[\"data\"], batch[\"target\"]\n","            x = to_device(x, device)\n","            with torch.no_grad(), amp.autocast(use_amp):\n","                y = model(x)\n","            y = y.detach().cpu().to(torch.float32)\n","            loss_func_val(y, t)\n","#             val_loss1 = loss_func_val.compute() \n","            bar.set_postfix(Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n","        val_loss = loss_func_val.compute()        \n","        if val_loss < best_val_loss:\n","            best_epoch = epoch\n","            best_val_loss = val_loss\n","            # print(\"save model\")\n","            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n","        \n","        elapsed_time = time() - epoch_start\n","        print(\n","            f\"[fold {fold_id}  epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f},best loss: {best_val_loss: .6f},best_epoch: {best_epoch}, elapsed_time: {elapsed_time: .3f}\")\n","        \n","        if epoch - best_epoch > CFG.es_patience:\n","            print(\"Early Stopping!\")\n","            break\n","            \n","        train_loss = 0\n","            \n","    return val_fold, best_epoch, best_val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mkdir /kaggle/working/stage1\n","!mkdir /kaggle/working/stage2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["score_list = []\n","for fold_id in FOLDS:\n","    output_path = Path(f\"./stage1/fold{fold_id}\")\n","    output_path.mkdir(exist_ok=True)\n","    print(f\"[fold{fold_id}]\")\n","    score_list.append(train_one_fold(CFG, fold_id, train, output_path,fold_id,1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(score_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_log_list = []\n","for (fold_id, best_epoch, _) in score_list:\n","    exp_dir_path = Path(f\"./stage1/fold{fold_id}\")\n","    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n","    copy_to = f\"./stage1/best_model_fold{fold_id}.pth\"\n","    shutil.copy(best_model_path, copy_to)\n","    \n","    for p in exp_dir_path.glob(\"*.pth\"):\n","        p.unlink()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = train_pop_2\n","train[\"fold\"] = -1\n","train.head(5)\n","sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n","\n","for fold_id, (_, val_idx) in enumerate(\n","    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n","):\n","    train.loc[val_idx, \"fold\"] = fold_id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["score_list = []\n","for fold_id in FOLDS:\n","    output_path = Path(f\"fold{fold_id}\")\n","    output_path.mkdir(exist_ok=True)\n","    print(f\"[fold{fold_id}]\")\n","    score_list.append(train_one_fold(CFG, fold_id, train, output_path,fold_id,2))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_log_list = []\n","for (fold_id, best_epoch, _) in score_list:\n","    exp_dir_path = Path(f\"./stage2/fold{fold_id}\")\n","    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n","    copy_to = f\"./stage2/best_model_fold{fold_id}.pth\"\n","    shutil.copy(best_model_path, copy_to)\n","    \n","    for p in exp_dir_path.glob(\"*.pth\"):\n","        p.unlink()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4472475,"sourceId":7668590,"sourceType":"datasetVersion"},{"datasetId":4664786,"sourceId":7935442,"sourceType":"datasetVersion"},{"datasetId":4681430,"sourceId":7958550,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
