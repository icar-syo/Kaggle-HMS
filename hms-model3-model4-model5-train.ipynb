{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T12:00:01.722299Z","iopub.status.busy":"2024-04-14T12:00:01.721941Z","iopub.status.idle":"2024-04-14T12:00:11.776212Z","shell.execute_reply":"2024-04-14T12:00:11.775411Z","shell.execute_reply.started":"2024-04-14T12:00:01.722269Z"},"trusted":true},"outputs":[],"source":["import sys\n","import os\n","import gc\n","import copy\n","import yaml\n","import random\n","import shutil\n","from time import time\n","import typing as tp\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import StratifiedGroupKFold\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.cuda import amp\n","\n","import timm\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:00:11.778717Z","iopub.status.busy":"2024-04-14T12:00:11.778113Z","iopub.status.idle":"2024-04-14T12:00:11.785823Z","shell.execute_reply":"2024-04-14T12:00:11.784926Z","shell.execute_reply.started":"2024-04-14T12:00:11.778683Z"},"trusted":true},"outputs":[],"source":["ROOT = Path.cwd().parent\n","INPUT = ROOT / \"input\"\n","OUTPUT = ROOT / \"output\"\n","SRC = ROOT / \"src\"\n","\n","DATA = INPUT / \"hms-harmful-brain-activity-classification\"\n","TRAIN_SPEC = DATA / \"train_spectrograms\"\n","TEST_SPEC = DATA / \"test_spectrograms\"\n","\n","TMP = ROOT / \"tmp\"\n","TMP.mkdir(exist_ok=True)\n","\n","RANDAM_SEED = 1086\n","CLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n","N_CLASSES = len(CLASSES)\n","FOLDS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","N_FOLDS = len(FOLDS)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:00:11.787293Z","iopub.status.busy":"2024-04-14T12:00:11.786995Z","iopub.status.idle":"2024-04-14T12:00:12.098818Z","shell.execute_reply":"2024-04-14T12:00:12.098029Z","shell.execute_reply.started":"2024-04-14T12:00:11.787269Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(DATA / \"train.csv\")\n","columns = ['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","# \n","train = train.drop_duplicates(subset=columns, keep='first').reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:00:12.101289Z","iopub.status.busy":"2024-04-14T12:00:12.100980Z","iopub.status.idle":"2024-04-14T12:00:12.122938Z","shell.execute_reply":"2024-04-14T12:00:12.121993Z","shell.execute_reply.started":"2024-04-14T12:00:12.101264Z"},"trusted":true},"outputs":[],"source":["train['total_votes'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n","train['target'] = train['expert_consensus']\n","train[CLASSES] /= train[CLASSES].sum(axis=1).values[:, None]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:00:12.124355Z","iopub.status.busy":"2024-04-14T12:00:12.124063Z","iopub.status.idle":"2024-04-14T12:00:12.129454Z","shell.execute_reply":"2024-04-14T12:00:12.128440Z","shell.execute_reply.started":"2024-04-14T12:00:12.124331Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n","    img_size = 512\n","    max_epoch = 10\n","    batch_size = 32\n","    lr = 1.0e-03\n","    weight_decay = 1.0e-02\n","    es_patience =  5\n","    seed = 1086\n","    deterministic = True\n","    enable_amp = True\n","    device = \"cuda\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:00:12.131526Z","iopub.status.busy":"2024-04-14T12:00:12.130827Z","iopub.status.idle":"2024-04-14T12:02:34.691514Z","shell.execute_reply":"2024-04-14T12:02:34.690534Z","shell.execute_reply.started":"2024-04-14T12:00:12.131494Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6.99 s, sys: 15.3 s, total: 22.3 s\n","Wall time: 2min 22s\n"]}],"source":["%%time\n","all_eeg2spec = np.load('/kaggle/input/eeg2spec-new/eeg2spec_new.npy',allow_pickle=True).item()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.693116Z","iopub.status.busy":"2024-04-14T12:02:34.692812Z","iopub.status.idle":"2024-04-14T12:02:34.729700Z","shell.execute_reply":"2024-04-14T12:02:34.728923Z","shell.execute_reply.started":"2024-04-14T12:02:34.693090Z"},"trusted":true},"outputs":[],"source":["max_int_value = (1 << 31) - 1\n","\n","keys_to_remove = []\n","\n","for key, value_list in list(all_eeg2spec.items()):\n","    if key <= 0:\n","        truncated_value = key\n","        n = 32  \n","        original_value = truncated_value + (1 << n)\n","        keys_to_remove.append(key)\n","        all_eeg2spec[original_value] = value_list\n","\n","for key in keys_to_remove:\n","    del all_eeg2spec[key]    "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.731079Z","iopub.status.busy":"2024-04-14T12:02:34.730818Z","iopub.status.idle":"2024-04-14T12:02:34.736870Z","shell.execute_reply":"2024-04-14T12:02:34.735985Z","shell.execute_reply.started":"2024-04-14T12:02:34.731054Z"},"trusted":true},"outputs":[],"source":["class HMSHBACSpecModel(nn.Module):\n","\n","    def __init__(\n","            self,\n","            model_name: str,\n","            pretrained: bool,\n","            in_channels: int,\n","            num_classes: int,\n","        ):\n","        super().__init__()\n","        self.model = timm.create_model(\n","            model_name=model_name, pretrained=pretrained,\n","            num_classes=num_classes, in_chans=in_channels)\n","\n","    def forward(self, x):\n","        h = self.model(x)      \n","\n","        return h"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.738371Z","iopub.status.busy":"2024-04-14T12:02:34.738068Z","iopub.status.idle":"2024-04-14T12:02:34.749401Z","shell.execute_reply":"2024-04-14T12:02:34.748522Z","shell.execute_reply.started":"2024-04-14T12:02:34.738347Z"},"trusted":true},"outputs":[],"source":["FilePath = tp.Union[str, Path]\n","EegIds = tp.Union[str, Path]\n","Label = tp.Union[int, float, np.ndarray]\n","\n","class HMSHBACSpecDataset(torch.utils.data.Dataset):\n","\n","    def __init__(\n","        self,\n","        eeg_ids: tp.Sequence[EegIds],\n","        label_ids: tp.Sequence[FilePath],\n","        labels: tp.Sequence[Label],\n","        transform: A.Compose,\n","    ):\n","        self.eeg_ids = eeg_ids\n","        self.label_ids = label_ids\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.label_ids)\n","\n","    def __getitem__(self, index: int):\n","        img_path = self.label_ids[index]\n","        label = self.labels[index]\n","        data = all_eeg2spec[img_path]\n","        mask = np.isnan(data)\n","        data[mask] = -1\n","        data = np.clip(data, np.exp(-6), np.exp(10))\n","        data = np.log(data)\n","        data_mean = data.mean(axis=(0, 1))\n","        data = data - data_mean\n","        img_std = data.std(axis=(0, 1))\n","        eps = 1e-6\n","        data = data / (img_std + eps)   \n","        data = data[..., None]\n","        img = self._apply_transform(data)\n","        return {\"data\": img, \"target\": label}\n","\n","    def _apply_transform(self, img: np.ndarray):\n","        \"\"\"apply transform to image and mask\"\"\"\n","        transformed = self.transform(image=img)\n","        img = transformed[\"image\"]\n","        return img"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.753596Z","iopub.status.busy":"2024-04-14T12:02:34.753222Z","iopub.status.idle":"2024-04-14T12:02:34.763246Z","shell.execute_reply":"2024-04-14T12:02:34.762464Z","shell.execute_reply.started":"2024-04-14T12:02:34.753553Z"},"trusted":true},"outputs":[],"source":["class KLDivLossWithLogits(nn.KLDivLoss):\n","\n","    def __init__(self):\n","        super().__init__(reduction=\"batchmean\")\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y,  dim=1)\n","        loss = super().forward(y, t)\n","\n","        return loss\n","\n","\n","class KLDivLossWithLogitsForVal(nn.KLDivLoss):\n","    \n","    def __init__(self):\n","        \"\"\"\"\"\"\n","        super().__init__(reduction=\"batchmean\")\n","        self.log_prob_list  = []\n","        self.label_list = []\n","\n","    def forward(self, y, t):\n","        y = nn.functional.log_softmax(y, dim=1)\n","        self.log_prob_list.append(y.numpy())\n","        self.label_list.append(t.numpy())\n","        \n","    def compute(self):\n","        log_prob = np.concatenate(self.log_prob_list, axis=0)\n","        label = np.concatenate(self.label_list, axis=0)\n","        final_metric = super().forward(\n","            torch.from_numpy(log_prob),\n","            torch.from_numpy(label)\n","        ).item()\n","        self.log_prob_list = []\n","        self.label_list = []\n","        \n","        return final_metric"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.764926Z","iopub.status.busy":"2024-04-14T12:02:34.764562Z","iopub.status.idle":"2024-04-14T12:02:34.776950Z","shell.execute_reply":"2024-04-14T12:02:34.776173Z","shell.execute_reply.started":"2024-04-14T12:02:34.764895Z"},"trusted":true},"outputs":[],"source":["def set_random_seed(seed: int = 42, deterministic: bool = False):\n","    \"\"\"Set seeds\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n","    \n","def to_device(\n","    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n","    device: torch.device, *args, **kwargs\n","):\n","    if isinstance(tensors, tuple):\n","        return (t.to(device, *args, **kwargs) for t in tensors)\n","    elif isinstance(tensors, dict):\n","        return {\n","            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n","    else:\n","        return tensors.to(device, *args, **kwargs)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.778381Z","iopub.status.busy":"2024-04-14T12:02:34.778024Z","iopub.status.idle":"2024-04-14T12:02:34.792666Z","shell.execute_reply":"2024-04-14T12:02:34.791754Z","shell.execute_reply.started":"2024-04-14T12:02:34.778357Z"},"trusted":true},"outputs":[],"source":["def time_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用时间遮蔽。\n","    \n","    参数：\n","    - spec: 输入的频谱图，形状为 \n","    - max_time_mask: 最大的时间遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用时间遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = time_steps - int(max_mask*time_steps)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*time_steps))\n","    masked_spec[:, mask_start:mask_end, :] = 0\n","    return masked_spec\n","\n","\n","def freq_masking(spec, max_mask=0.2):\n","    \"\"\"\n","    对频谱图应用频率遮蔽。\n","    参数：\n","    - spec: 输入的频谱图，形状为 \n","    - max_freq_mask: 最大的频率遮蔽长度\n","    \n","    返回值：\n","    - masked_spec: 应用频率遮蔽后的频谱图\n","    \"\"\"\n","    freq_bins,time_steps,channels = spec.shape\n","    masked_spec = spec.copy()\n","    max_mask_start = freq_bins - int(max_mask*freq_bins)\n","    mask_start = np.random.randint(0, max_mask_start)\n","    mask_end = mask_start + np.random.randint(0, int(max_mask*freq_bins))\n","    masked_spec[mask_start:mask_end, :, :] = 0\n","    return masked_spec\n","\n","\n","class TimeMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(TimeMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, image, **params):\n","        return time_masking(image, self.max_mask)\n","\n","class FreqMasking(A.DualTransform):\n","    def __init__(self, max_mask=0.2, always_apply=False, p=0.5):\n","        super(FreqMasking, self).__init__(always_apply, p)\n","        self.max_mask = max_mask\n","\n","    def apply(self, spec, **params):\n","        return freq_masking(spec, self.max_mask)\n","def get_transforms(CFG):\n","    train_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        TimeMasking(max_mask=0.2, p=0.5),\n","        FreqMasking(max_mask=0.2, p=0.5),\n","        ToTensorV2(p=1.0)\n","    ])\n","    val_transform = A.Compose([\n","        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n","        ToTensorV2(p=1.0)\n","    ])\n","    return train_transform, val_transform"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.794125Z","iopub.status.busy":"2024-04-14T12:02:34.793774Z","iopub.status.idle":"2024-04-14T12:02:34.805801Z","shell.execute_reply":"2024-04-14T12:02:34.804931Z","shell.execute_reply.started":"2024-04-14T12:02:34.794085Z"},"trusted":true},"outputs":[],"source":["def get_path_label(val_fold, train_all: pd.DataFrame):\n","    \"\"\"Get file path and target info.\"\"\"\n","    train_idx = train_all[train_all[\"fold\"] != val_fold].index.values\n","    val_idx   = train_all[train_all[\"fold\"] == val_fold].index.values\n","    label_ids = []\n","    eeg_ids = []\n","    labels = train_all[CLASSES].values\n","    for label_id in train_all[\"label_id\"].values:\n","        train1 = train[train['label_id']==label_id]\n","        eeg_id = train1['eeg_id'].values[0]\n","        eeg_ids.append(eeg_id)\n","        label_ids.append(label_id)\n","\n","    train_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in train_idx],\n","        \"label_ids\": [label_ids[idx] for idx in train_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in train_idx]}\n","\n","    val_data = {\n","        \"eeg_ids\": [eeg_ids[idx] for idx in val_idx],\n","        \"label_ids\": [label_ids[idx] for idx in val_idx],\n","        \"labels\": [labels[idx].astype(\"float32\") for idx in val_idx]}\n","    \n","    return train_data, val_data, train_idx, val_idx\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.807093Z","iopub.status.busy":"2024-04-14T12:02:34.806846Z","iopub.status.idle":"2024-04-14T12:02:34.827265Z","shell.execute_reply":"2024-04-14T12:02:34.826452Z","shell.execute_reply.started":"2024-04-14T12:02:34.807071Z"},"trusted":true},"outputs":[],"source":["def train_one_fold(CFG, val_fold, train_all, output_path,fold_id,stage_id):\n","    \"\"\"Main\"\"\"\n","    torch.backends.cudnn.benchmark = True\n","    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n","    device = torch.device(CFG.device)\n","    \n","    train_path_label, val_path_label, _, _ = get_path_label(val_fold, train_all)\n","    train_transform, val_transform = get_transforms(CFG)\n","    \n","    train_dataset = HMSHBACSpecDataset(**train_path_label, transform=train_transform)\n","    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n","    \n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n","    val_loader = torch.utils.data.DataLoader(\n","        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n","    \n","    model = HMSHBACSpecModel(\n","        model_name=CFG.model_name, pretrained=True, num_classes=6, in_channels=1)\n","    if stage_id == 2:\n","        model.load_state_dict(torch.load(f'./stage1/best_model_fold{val_fold}.pth', map_location=device))\n","    model.to(device)\n","    \n","    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    scheduler = lr_scheduler.OneCycleLR(\n","        optimizer=optimizer, epochs=CFG.max_epoch,\n","        pct_start=0.0, steps_per_epoch=len(train_loader),\n","        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n","    )\n","    \n","    loss_func = KLDivLossWithLogits()\n","    loss_func.to(device)\n","    loss_func_val = KLDivLossWithLogitsForVal()\n","    \n","    use_amp = CFG.enable_amp\n","    scaler = amp.GradScaler(enabled=use_amp)\n","    \n","    best_val_loss = 1.0e+09\n","    best_epoch = 0\n","    train_loss = 0\n","    \n","    for epoch in range(1, CFG.max_epoch + 1):\n","        epoch_start = time()\n","        model.train()\n","        bar = tqdm(enumerate(train_loader), total=len(train_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","            batch = to_device(batch, device)\n","            x, t = batch[\"data\"], batch[\"target\"]\n","                \n","            optimizer.zero_grad()\n","            with amp.autocast(use_amp):\n","                y = model(x)\n","                loss = loss_func(y, t)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            train_loss += loss.item()\n","            loss_show = float(train_loss/bs)\n","            bar.set_postfix(Epoch=epoch, Train_Loss=loss_show, LR=optimizer.param_groups[0]['lr'])\n","\n","        train_loss /= len(train_loader)\n","            \n","        model.eval()\n","        bar = tqdm(enumerate(val_loader), total=len(val_loader))\n","        bs = 0 \n","        for step, batch in bar:\n","            bs+=1\n","            x, t = batch[\"data\"], batch[\"target\"]\n","            x = to_device(x, device)\n","            with torch.no_grad(), amp.autocast(use_amp):\n","                y = model(x)\n","            y = y.detach().cpu().to(torch.float32)\n","            loss_func_val(y, t)\n","            bar.set_postfix(Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n","        val_loss = loss_func_val.compute()        \n","        if val_loss < best_val_loss:\n","            best_epoch = epoch\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n","        \n","        elapsed_time = time() - epoch_start\n","        print(\n","            f\"[fold {fold_id}  epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f},best loss: {best_val_loss: .6f},best_epoch: {best_epoch}, elapsed_time: {elapsed_time: .3f}\")\n","        \n","        if epoch - best_epoch > CFG.es_patience:\n","            print(\"Early Stopping!\")\n","            break\n","            \n","        train_loss = 0\n","            \n","    return val_fold, best_epoch, best_val_loss"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:34.828639Z","iopub.status.busy":"2024-04-14T12:02:34.828374Z","iopub.status.idle":"2024-04-14T12:02:36.637648Z","shell.execute_reply":"2024-04-14T12:02:36.636659Z","shell.execute_reply.started":"2024-04-14T12:02:34.828615Z"},"trusted":true},"outputs":[],"source":["pop_1_idx = train['total_votes'] < 10\n","train_pop_1 = train[pop_1_idx].copy().reset_index(drop=True)\n","train_pop_2 = train[~pop_1_idx].copy().reset_index(drop=True)\n","train = train_pop_1\n","train[\"fold\"] = -1\n","train.head(5)\n","sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n","\n","for fold_id, (_, val_idx) in enumerate(\n","    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n","):\n","    train.loc[val_idx, \"fold\"] = fold_id"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:36.639449Z","iopub.status.busy":"2024-04-14T12:02:36.638873Z","iopub.status.idle":"2024-04-14T12:02:39.411532Z","shell.execute_reply":"2024-04-14T12:02:39.410389Z","shell.execute_reply.started":"2024-04-14T12:02:36.639415Z"},"trusted":true},"outputs":[],"source":["!mkdir /kaggle/working/stage1\n","!mkdir /kaggle/working/stage2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:02:39.413700Z","iopub.status.busy":"2024-04-14T12:02:39.413257Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[fold0]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8131903788ff412abea319a50b807c7c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ddd391f7cf743239c8bcbb014dc03f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/393 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ea3f0a0a60e440399e70b2846bab3b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/39 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 0  epoch 1] train loss:  1.070004, val loss:  0.723159,best loss:  0.723159,best_epoch: 1, elapsed_time:  362.616\n","[fold1]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5135bbfd958e4e1fb21ada24692c67a7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d905c332f414611aaac1276fafc39aa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 1  epoch 1] train loss:  1.028920, val loss:  0.816663,best loss:  0.816663,best_epoch: 1, elapsed_time:  343.458\n","[fold2]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a98e98665a4409851f1db3a75092b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/398 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18ae722f33db40cfa790f7782524799c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/34 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 2  epoch 1] train loss:  0.909996, val loss:  0.703254,best loss:  0.703254,best_epoch: 1, elapsed_time:  349.889\n","[fold3]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d79935317044648960e40df1e10a01a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99b780248374453693cc40ff60b5678a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/43 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 3  epoch 1] train loss:  1.029500, val loss:  0.739005,best loss:  0.739005,best_epoch: 1, elapsed_time:  344.229\n","[fold4]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbc14b1bf24b4f72922a4782266773d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/373 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23c60b61ea7140bca492430d3003e058","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/59 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 4  epoch 1] train loss:  1.061240, val loss:  1.151923,best loss:  1.151923,best_epoch: 1, elapsed_time:  334.072\n","[fold5]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1952291192c41ffa4d60c5f72ff6ba9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c440af0f887d4bdebd417e873d13bc90","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/43 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 5  epoch 1] train loss:  0.927855, val loss:  0.870677,best loss:  0.870677,best_epoch: 1, elapsed_time:  344.604\n","[fold6]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d96fe24e08864ae0b181f4f91f1f8278","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9c7cc7755f94c319445f793d8d5bed9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/42 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 6  epoch 1] train loss:  0.894146, val loss:  0.718262,best loss:  0.718262,best_epoch: 1, elapsed_time:  345.034\n","[fold7]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad35ed582bd540aaaed97ed6dbc010c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2b2a33d7ff04edcbfefb8001648c61a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/41 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 7  epoch 1] train loss:  0.983522, val loss:  0.737169,best loss:  0.737169,best_epoch: 1, elapsed_time:  344.459\n","[fold8]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4ad0f1d12374e569f8f4c4c90628ed9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/387 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd2aec7aaa6943dda3870f23dd14d18a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/45 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[fold 8  epoch 1] train loss:  1.045373, val loss:  0.869308,best loss:  0.869308,best_epoch: 1, elapsed_time:  343.870\n","[fold9]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2af79471d65e491785617318c4b9151a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/384 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]}],"source":["score_list = []\n","for fold_id in FOLDS:\n","    output_path = Path(f\"./stage1/fold{fold_id}\")\n","    output_path.mkdir(exist_ok=True)\n","    print(f\"[fold{fold_id}]\")\n","    score_list.append(train_one_fold(CFG, fold_id, train, output_path,fold_id,1))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["best_log_list = []\n","for (fold_id, best_epoch, _) in score_list:\n","    exp_dir_path = Path(f\"./stage1/fold{fold_id}\")\n","    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n","    copy_to = f\"./stage1/best_model_fold{fold_id}.pth\"\n","    shutil.copy(best_model_path, copy_to)\n","    \n","    for p in exp_dir_path.glob(\"*.pth\"):\n","        p.unlink()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = train_pop_2\n","train[\"fold\"] = -1\n","train.head(5)\n","sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n","\n","for fold_id, (_, val_idx) in enumerate(\n","    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n","):\n","    train.loc[val_idx, \"fold\"] = fold_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["score_list = []\n","for fold_id in FOLDS:\n","    output_path = Path(f\"fold{fold_id}\")\n","    output_path.mkdir(exist_ok=True)\n","    print(f\"[fold{fold_id}]\")\n","    score_list.append(train_one_fold(CFG, fold_id, train, output_path,fold_id,2))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["best_log_list = []\n","for (fold_id, best_epoch, _) in score_list:\n","    exp_dir_path = Path(f\"./stage2/fold{fold_id}\")\n","    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n","    copy_to = f\"./stage2/best_model_fold{fold_id}.pth\"\n","    shutil.copy(best_model_path, copy_to)\n","    \n","    for p in exp_dir_path.glob(\"*.pth\"):\n","        p.unlink()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4664786,"sourceId":7935442,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
